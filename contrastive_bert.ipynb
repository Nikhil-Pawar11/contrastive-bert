{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tK186vufiEt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y fsspec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORIxni9igC2e",
        "outputId": "978d9084-1b43-4da4-9f2b-e1b099fff93b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: fsspec 2023.6.0\n",
            "Uninstalling fsspec-2023.6.0:\n",
            "  Successfully uninstalled fsspec-2023.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install fsspec==2023.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "dQmKihlmdgVf",
        "outputId": "56282dfb-b4d6-45a3-cc63-312723c3f7d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec==2023.6.0\n",
            "  Using cached fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "Installing collected packages: fsspec\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.6.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2023.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fsspec"
                ]
              },
              "id": "848feb45176d4ba9a43b04ac1b44de04"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1.1: Install required libraries (run only once)\n",
        "!pip install transformers datasets sentencepiece -q\n",
        "!pip install scikit-learn matplotlib -q\n",
        "\n",
        "# Step 1.2: Check if GPU is available\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO8tQ2gPfidG",
        "outputId": "801ba7fc-680a-4ba1-a541-80b6a50cb6c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NWvwb2R4fiiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYvUU5l6dcyz",
        "outputId": "acfa8276-69f7-4b2c-8429-a03cd4f5c34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Positive pairs: 1406, Negative pairs: 1967\n",
            "Total pairs after augmentation: 3000\n",
            "🟢 Vanilla BERT Spearman Correlation: 0.3174\n",
            "Epoch 1: Avg InfoNCE Loss = 0.5631\n",
            "Epoch 2: Avg InfoNCE Loss = 0.2905\n",
            "Epoch 3: Avg InfoNCE Loss = 0.1966\n",
            "🔍 Spearman Correlation after contrastive training: 0.7600\n",
            "✅ Model saved to: /content/saved_model\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --------------------------\n",
        "# Install dependencies\n",
        "# --------------------------\n",
        "!pip install transformers datasets sentencepiece -q\n",
        "!pip install scikit-learn matplotlib nltk -q\n",
        "# --------------------------\n",
        "# Imports and GPU check\n",
        "# --------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr\n",
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --------------------------\n",
        "# Load STS-B dataset\n",
        "# --------------------------\n",
        "dataset = load_dataset(\"glue\", \"stsb\")\n",
        "df = dataset[\"train\"].to_pandas()\n",
        "positive_pairs = df[df[\"label\"] >= 4.0][[\"sentence1\", \"sentence2\"]].reset_index(drop=True)\n",
        "negative_pairs = df[df[\"label\"] <= 2.0][[\"sentence1\", \"sentence2\"]].reset_index(drop=True)\n",
        "print(f\"Positive pairs: {len(positive_pairs)}, Negative pairs: {len(negative_pairs)}\")\n",
        "\n",
        "# --------------------------\n",
        "# Data Augmentation function\n",
        "# --------------------------\n",
        "def synonym_replacement(sentence, n=1):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    candidates = list(set([word for word in words if wordnet.synsets(word)]))\n",
        "    if not candidates:\n",
        "        return sentence\n",
        "    count = 0\n",
        "    while count < n:\n",
        "        word = random.choice(candidates)\n",
        "        synonyms = wordnet.synsets(word)\n",
        "        if synonyms:\n",
        "            syn_words = synonyms[0].lemma_names()\n",
        "            if syn_words:\n",
        "                synonym = syn_words[0].replace(\"_\", \" \")\n",
        "                new_words = [synonym if w == word else w for w in new_words]\n",
        "                count += 1\n",
        "    return \" \".join(new_words)\n",
        "\n",
        "# --------------------------\n",
        "# Create augmented pairs\n",
        "# --------------------------\n",
        "N = 1000\n",
        "positive_samples = positive_pairs.sample(N, random_state=42)\n",
        "negative_samples = negative_pairs.sample(N, random_state=42)\n",
        "positive_samples[\"label\"] = 1\n",
        "negative_samples[\"label\"] = 0\n",
        "\n",
        "augmented_sentences = []\n",
        "for _, row in positive_samples.iterrows():\n",
        "    aug_s1 = synonym_replacement(row[\"sentence1\"], n=1)\n",
        "    augmented_sentences.append({\"sentence1\": aug_s1, \"sentence2\": row[\"sentence2\"], \"label\": 1})\n",
        "\n",
        "aug_df = pd.DataFrame(augmented_sentences)\n",
        "positive_aug = pd.concat([positive_samples, aug_df]).reset_index(drop=True)\n",
        "combined_pairs = pd.concat([positive_aug, negative_samples]).sample(frac=1).reset_index(drop=True)\n",
        "print(f\"Total pairs after augmentation: {len(combined_pairs)}\")\n",
        "\n",
        "# --------------------------\n",
        "# Tokenizer\n",
        "# --------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# --------------------------\n",
        "# Dataset and DataLoader\n",
        "# --------------------------\n",
        "class ContrastivePairDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.sentence1 = list(df[\"sentence1\"])\n",
        "        self.sentence2 = list(df[\"sentence2\"])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentence1[idx], self.sentence2[idx]\n",
        "\n",
        "aug_dataset = ContrastivePairDataset(combined_pairs)\n",
        "aug_dataloader = DataLoader(aug_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# --------------------------\n",
        "# Contrastive Model\n",
        "# --------------------------\n",
        "class ContrastiveModel(nn.Module):\n",
        "    def __init__(self, model_name=\"bert-base-uncased\"):\n",
        "        super(ContrastiveModel, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        cls_embeddings = output.last_hidden_state[:, 0]\n",
        "        return cls_embeddings\n",
        "\n",
        "def info_nce_loss(emb1, emb2, temperature=0.05):\n",
        "    emb1 = F.normalize(emb1, dim=1)\n",
        "    emb2 = F.normalize(emb2, dim=1)\n",
        "    sim_matrix = torch.matmul(emb1, emb2.T) / temperature\n",
        "    batch_size = emb1.size(0)\n",
        "    labels = torch.arange(batch_size).to(emb1.device)\n",
        "    loss = F.cross_entropy(sim_matrix, labels)\n",
        "    return loss\n",
        "\n",
        "# --------------------------\n",
        "# Vanilla BERT baseline\n",
        "# --------------------------\n",
        "class VanillaBERTModel(nn.Module):\n",
        "    def __init__(self, model_name=\"bert-base-uncased\"):\n",
        "        super(VanillaBERTModel, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        return output.last_hidden_state[:, 0]\n",
        "\n",
        "# Evaluate vanilla BERT\n",
        "sts_val = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n",
        "df_val = sts_val.to_pandas()[[\"sentence1\", \"sentence2\", \"label\"]].dropna().reset_index(drop=True)\n",
        "vanilla_model = VanillaBERTModel().to(device)\n",
        "vanilla_model.eval()\n",
        "\n",
        "batch_size = 64\n",
        "cos_sims_base = []\n",
        "for i in range(0, len(df_val), batch_size):\n",
        "    batch_s1 = df_val[\"sentence1\"][i:i+batch_size].tolist()\n",
        "    batch_s2 = df_val[\"sentence2\"][i:i+batch_size].tolist()\n",
        "    enc1 = tokenizer(batch_s1, padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
        "    enc2 = tokenizer(batch_s2, padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        emb1 = vanilla_model(enc1[\"input_ids\"], enc1[\"attention_mask\"], enc1[\"token_type_ids\"])\n",
        "        emb2 = vanilla_model(enc2[\"input_ids\"], enc2[\"attention_mask\"], enc2[\"token_type_ids\"])\n",
        "    sim = cosine_similarity(emb1.cpu(), emb2.cpu()).diagonal()\n",
        "    cos_sims_base.extend(sim)\n",
        "\n",
        "true_scores = df_val[\"label\"].values / 5.0\n",
        "pred_scores_base = np.array(cos_sims_base)\n",
        "corr_base, _ = spearmanr(true_scores, pred_scores_base)\n",
        "print(f\"🟢 Vanilla BERT Spearman Correlation: {corr_base:.4f}\")\n",
        "\n",
        "# --------------------------\n",
        "# Train contrastive model\n",
        "# --------------------------\n",
        "model = ContrastiveModel().to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for batch in aug_dataloader:\n",
        "        sent1, sent2 = batch\n",
        "        enc1 = tokenizer(list(sent1), padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
        "        enc2 = tokenizer(list(sent2), padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
        "        emb1 = model(enc1[\"input_ids\"], enc1[\"attention_mask\"], enc1[\"token_type_ids\"])\n",
        "        emb2 = model(enc2[\"input_ids\"], enc2[\"attention_mask\"], enc2[\"token_type_ids\"])\n",
        "        loss = info_nce_loss(emb1, emb2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(aug_dataloader)\n",
        "    print(f\"Epoch {epoch+1}: Avg InfoNCE Loss = {avg_loss:.4f}\")\n",
        "\n",
        "# --------------------------\n",
        "# Evaluate trained model\n",
        "# --------------------------\n",
        "model.eval()\n",
        "cos_sims = []\n",
        "for i in range(0, len(df_val), batch_size):\n",
        "    batch_s1 = df_val[\"sentence1\"][i:i+batch_size].tolist()\n",
        "    batch_s2 = df_val[\"sentence2\"][i:i+batch_size].tolist()\n",
        "    enc1 = tokenizer(batch_s1, padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
        "    enc2 = tokenizer(batch_s2, padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        emb1 = model(enc1[\"input_ids\"], enc1[\"attention_mask\"], enc1[\"token_type_ids\"])\n",
        "        emb2 = model(enc2[\"input_ids\"], enc2[\"attention_mask\"], enc2[\"token_type_ids\"])\n",
        "    sim = cosine_similarity(emb1.cpu(), emb2.cpu()).diagonal()\n",
        "    cos_sims.extend(sim)\n",
        "\n",
        "pred_scores = np.array(cos_sims)\n",
        "corr, _ = spearmanr(true_scores, pred_scores)\n",
        "print(f\"🔍 Spearman Correlation after contrastive training: {corr:.4f}\")\n",
        "\n",
        "model_path = \"/content/saved_model\"\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "tokenizer.save_pretrained(model_path)\n",
        "model.bert.save_pretrained(model_path)\n",
        "print(\"✅ Model saved to:\", model_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G50Ht60qdgdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhUbHC7qdgf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5y4hGYIdgh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}